{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62bba457-3078-428a-a4ef-e89140584278",
   "metadata": {},
   "source": [
    "***AI Engineer - P9 - D√©veloppez une preuve de concept***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61033d0-62f3-4905-88eb-2b8e21960fc1",
   "metadata": {},
   "source": [
    "# Importation des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0237a702-1939-4d54-90c0-bb86ead2f6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14405add-7926-4c73-9169-ba39ae3428ce",
   "metadata": {},
   "source": [
    "# Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b875829-b63a-4fea-b8f3-4a5bbcf8d590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion en Dataset\n",
    "def encode_data(encodings, labels):\n",
    "    return Dataset.from_dict({\n",
    "        'input_ids': encodings['input_ids'],\n",
    "        'attention_mask': encodings['attention_mask'],\n",
    "        'labels': labels\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b990ece5-06a8-488a-be51-0dc88728733b",
   "metadata": {},
   "source": [
    "# Chargement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4be43786-a7ae-481a-9aaa-1f4dcceb107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv(\"df_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9745a78-2963-4618-a44d-6f8f0ef7ec23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   target                                               text  \\\n",
      "0       1  I kinda use the Tweetie video feat., I would u...   \n",
      "1       0  i want the new album so bad!! but i cant get i...   \n",
      "2       0  Man... I think Dan is going to make me see Los...   \n",
      "3       0      Played a bad game with hockey today, lost 7-5   \n",
      "4       1  wow! i had a great sleep. good morning everyon...   \n",
      "\n",
      "                                            text_bow  \\\n",
      "0  kinda use tweetie video feat would use audio o...   \n",
      "1                  want new album bad cant get today   \n",
      "2  man think dan going make see los campesinos au...   \n",
      "3                  played bad game hockey today lost   \n",
      "4  wow great sleep good morning everyone hehe nic...   \n",
      "\n",
      "                                        text_bow_lem  \\\n",
      "0  kinda use tweetie video feat would use audio o...   \n",
      "1                  want new album bad cant get today   \n",
      "2  man think dan going make see los campesinos au...   \n",
      "3                  played bad game hockey today lost   \n",
      "4  wow great sleep good morning everyone hehe nic...   \n",
      "\n",
      "                                       text_bow_stem  \\\n",
      "0  kinda use tweeti video feat would use audio of...   \n",
      "1                  want new album bad cant get today   \n",
      "2      man think dan go make see lo campesino august   \n",
      "3                    play bad game hockey today lost   \n",
      "4    wow great sleep good morn everyon hehe nice day   \n",
      "\n",
      "                                             text_dl  \n",
      "0  i kinda use the tweetie video feat i would use...  \n",
      "1  i want the new album so bad but i cant get it ...  \n",
      "2  man i think dan is going to make me see los ca...  \n",
      "3       played a bad game with hockey today lost 7 5  \n",
      "4  wow i had a great sleep good morning everyone ...  \n"
     ]
    }
   ],
   "source": [
    "# V√©rification du DataFrame\n",
    "print(df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f583104-ed87-4d77-8a4d-0ff32c2662b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©parer les donn√©es\n",
    "X = df_final['text']\n",
    "y = df_final['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f47692-c135-4330-b2b8-f7a8af2fa6d9",
   "metadata": {},
   "source": [
    "# Chargement des mod√®les existants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f24674df-c7e2-4942-961d-a8afb2c04f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Tf-idf_MLP-Classifier_model.pkl\", \"rb\") as f:\n",
    "    mlp_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbae6101-d08f-4f7e-b61c-cc98fe496d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tfidf_model.pkl\", \"rb\") as f:\n",
    "    tfidf_vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1868a05-a9ad-4a01-a6a8-1a4430f93183",
   "metadata": {},
   "source": [
    "# Pr√©dictions avec le mod√®le MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a319145-f5c2-4eb4-8648-b73ab4f84670",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "mlp_predictions = mlp_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4193f668-a6b7-45c4-abc8-454554f8ac5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MLP Classifier avec Tf-idf ===\n",
      "Accuracy: 0.6993\n",
      "F1 Score: 0.6785\n",
      "AUC: 0.7064\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.45      0.60      2055\n",
      "           1       0.62      0.97      0.76      1945\n",
      "\n",
      "    accuracy                           0.70      4000\n",
      "   macro avg       0.78      0.71      0.68      4000\n",
      "weighted avg       0.78      0.70      0.68      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calcul des m√©triques pour la baseline\n",
    "print(\"\\n=== MLP Classifier ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, mlp_predictions):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, mlp_predictions, average='weighted'):.4f}\")\n",
    "print(f\"AUC: {roc_auc_score(y_test, mlp_predictions):.4f}\")\n",
    "print(classification_report(y_test, mlp_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ef020f-09cb-4fb3-96b4-aae062446d5a",
   "metadata": {},
   "source": [
    "# Pr√©dictions avec DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9196b99c-ae65-4b77-baf4-54ceaf63c429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialisation de DistilBERT\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfe94f6a-ea93-4255-b220-ff18e07f99aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©paration des donn√©es pour DistilBERT\n",
    "train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d01d512f-8269-4add-87cc-7419fa12abfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = encode_data(train_encodings, list(y_train))\n",
    "test_dataset = encode_data(test_encodings, list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f560fc88-1423-46a7-ba80-a3743fee10b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\anaconda3\\envs\\oc_p9\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Entra√Æner le mod√®le DistilBERT\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28a5aeca-23d7-4c1e-924d-4a9cbaf5dc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 2:30:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.422100</td>\n",
       "      <td>0.413466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.307700</td>\n",
       "      <td>0.432768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.219100</td>\n",
       "      <td>0.531560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3000, training_loss=0.3253490473429362, metrics={'train_runtime': 9013.7732, 'train_samples_per_second': 5.325, 'train_steps_per_second': 0.333, 'total_flos': 1589608783872000.0, 'train_loss': 0.3253490473429362, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a6f5ad4-7859-4954-ac4a-be21a2323279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mod√®le et tokenizer sauvegard√©s dans le r√©pertoire : ./distilbert_finetuned\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder le mod√®le fine-tun√© et le tokenizer\n",
    "output_dir = \"./distilbert_finetuned\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"Mod√®le et tokenizer sauvegard√©s dans le r√©pertoire : {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f33abf46-b162-4466-a673-c5d2286bb2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# √âvaluer le mod√®le DistilBERT\n",
    "predictions = trainer.predict(test_dataset)\n",
    "pred_labels = torch.argmax(torch.tensor(predictions.predictions), axis=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fead24dc-0736-4095-8ddf-85b9f0e41c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DistilBERT ===\n",
      "Accuracy: 0.8227\n",
      "F1 Score: 0.8228\n",
      "AUC: 0.8230\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      2055\n",
      "           1       0.81      0.83      0.82      1945\n",
      "\n",
      "    accuracy                           0.82      4000\n",
      "   macro avg       0.82      0.82      0.82      4000\n",
      "weighted avg       0.82      0.82      0.82      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calcul des m√©triques pour DistilBERT\n",
    "print(\"\\n=== DistilBERT ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, pred_labels):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, pred_labels, average='weighted'):.4f}\")\n",
    "print(f\"AUC: {roc_auc_score(y_test, pred_labels):.4f}\")\n",
    "print(classification_report(y_test, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd821484-2ce5-44e7-9243-fffb7c6bdba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le mod√®le entra√Æn√©\n",
    "output_dir = \"distilbert_finetuned\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
